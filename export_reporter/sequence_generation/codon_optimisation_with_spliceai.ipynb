{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gzip\n",
    "import random\n",
    "import argparse\n",
    "from os.path import exists\n",
    "import sys\n",
    "import itertools\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_cds(cds):\n",
    "    map = {\"TTT\": \"F\", \"TTC\": \"F\", \"TTA\": \"L\", \"TTG\": \"L\",\n",
    "           \"TCT\": \"S\", \"TCC\": \"S\", \"TCA\": \"S\", \"TCG\": \"S\",\n",
    "           \"TAT\": \"Y\", \"TAC\": \"Y\",\n",
    "           \"TGT\": \"C\", \"TGC\": \"C\", \"TGG\": \"W\",\n",
    "           \"CTT\": \"L\", \"CTC\": \"L\", \"CTA\": \"L\", \"CTG\": \"L\",\n",
    "           \"CCT\": \"P\", \"CCC\": \"P\", \"CCA\": \"P\", \"CCG\": \"P\",\n",
    "           \"CAT\": \"H\", \"CAC\": \"H\", \"CAA\": \"Q\", \"CAG\": \"Q\",\n",
    "           \"CGT\": \"R\", \"CGC\": \"R\", \"CGA\": \"R\", \"CGG\": \"R\",\n",
    "           \"ATT\": \"I\", \"ATC\": \"I\", \"ATA\": \"I\", \"ATG\": \"M\",\n",
    "           \"ACT\": \"T\", \"ACC\": \"T\", \"ACA\": \"T\", \"ACG\": \"T\",\n",
    "           \"AAT\": \"N\", \"AAC\": \"N\", \"AAA\": \"K\", \"AAG\": \"K\",\n",
    "           \"AGT\": \"S\", \"AGC\": \"S\", \"AGA\": \"R\", \"AGG\": \"R\",\n",
    "           \"GTT\": \"V\", \"GTC\": \"V\", \"GTA\": \"V\", \"GTG\": \"V\",\n",
    "           \"GCT\": \"A\", \"GCC\": \"A\", \"GCA\": \"A\", \"GCG\": \"A\",\n",
    "           \"GAT\": \"D\", \"GAC\": \"D\", \"GAA\": \"E\", \"GAG\": \"E\",\n",
    "           \"GGT\": \"G\", \"GGC\": \"G\", \"GGA\": \"G\", \"GGG\": \"G\"}\n",
    "\n",
    "    aa_seq = \"\"\n",
    "    for i in range(int(len(cds) / 3)):\n",
    "        aa_seq += map[cds.upper()[3 * i:3 * i + 3]]\n",
    "\n",
    "    return aa_seq\n",
    "\n",
    "\n",
    "def make_nt_seq(aa_seq, pptness = False):\n",
    "    import random\n",
    "    # d = {\"A\": [\"GCA\", \"GCC\", \"GCT\", \"GCG\"]}\n",
    "\n",
    "    d = {\"A\": [\"GCT\", \"GCC\", \"GCA\", \"GCG\"], \"I\": [\"ATT\", \"ATC\", \"ATA\"],\n",
    "         \"R\": [\"CGT\", \"CGC\", \"CGA\", \"CGG\", \"AGA\", \"AGG\"], \"L\": [\"CTT\", \"CTC\", \"CTA\", \"CTG\", \"TTA\", \"TTG\"],\n",
    "         \"N\": [\"AAT\", \"AAC\"], \"K\": [\"AAA\", \"AAG\"], \"D\": [\"GAT\", \"GAC\"], \"M\": [\"ATG\"],\n",
    "         \"F\": [\"TTT\", \"TTC\"], \"C\": [\"TGT\", \"TGC\"], \"P\": [\"CCT\", \"CCC\", \"CCA\", \"CCG\"],\n",
    "         \"Q\": [\"CAA\", \"CAG\"], \"S\": [\"TCT\", \"TCC\", \"TCA\", \"TCG\", \"AGT\", \"AGC\"],\n",
    "         \"E\": [\"GAA\", \"GAG\"], \"T\": [\"ACT\", \"ACC\", \"ACA\", \"ACG\"],\n",
    "         \"W\": [\"TGG\"],\n",
    "         \"G\": [\"GGT\", \"GGC\", \"GGA\", \"GGG\"], \"Y\": [\"TAT\", \"TAC\"],\n",
    "         \"H\": [\"CAT\", \"CAC\"], \"V\": [\"GTT\", \"GTC\", \"GTA\", \"GTG\"]}\n",
    "\n",
    "    seq = \"\"\n",
    "    for aa in aa_seq:\n",
    "        if pptness == False:\n",
    "            seq += random.choice(d[aa])\n",
    "        else:\n",
    "            # Find the one with the most pyrimidines\n",
    "            potentials = d[aa]\n",
    "            random.shuffle(potentials)\n",
    "            best = -1\n",
    "            for codon in potentials:\n",
    "                pyr = codon.count(\"T\") + codon.count(\"C\")\n",
    "                if pyr > best:\n",
    "                    best = pyr\n",
    "                    best_codon = codon\n",
    "\n",
    "            seq += best_codon\n",
    "    # print(seq)\n",
    "\n",
    "    return seq\n",
    "\n",
    "def make_random_seq(l):\n",
    "    nts = [\"A\", \"C\", \"G\", \"T\"]\n",
    "\n",
    "    return ''.join(random.choices(nts, k=l))\n",
    "\n",
    "\n",
    "def make_ppt(l, frac):\n",
    "    s = \"\"\n",
    "    for _ in range(l):\n",
    "        if random.uniform(0, 1) <= frac:\n",
    "            s += random.choice([\"C\", \"T\"])\n",
    "        else:\n",
    "            s += random.choice([\"A\", \"G\"])\n",
    "\n",
    "    return s\n",
    "\n",
    "\n",
    "def random_mut(seq, rate, skip_splice_sites = True):\n",
    "    out = []\n",
    "    nts = [\"A\", \"C\", \"G\", \"T\"]\n",
    "\n",
    "    for i, s in enumerate(seq):\n",
    "        if i in [0, 1, len(seq)-2, len(seq)-1]:\n",
    "            out.append(s)\n",
    "        else:\n",
    "            if random.uniform(0, 1) <= rate:\n",
    "                out.append(random.choice(nts))\n",
    "            else:\n",
    "                out.append(s)\n",
    "\n",
    "    return ''.join(out)\n",
    "\n",
    "\n",
    "def remove_NY(initial_seq, pyrimidine_chance):\n",
    "    # Convert string to list\n",
    "    seq = list(initial_seq)\n",
    "    new_seq = seq\n",
    "\n",
    "    for i, character in enumerate(seq):\n",
    "        if character.upper() == \"N\":\n",
    "            new_seq[i] = random.choice([\"a\", \"t\", \"c\", \"g\"])\n",
    "        elif character.upper() == \"Y\":\n",
    "            new_seq[i] = make_ppt(1, pyrimidine_chance).lower()\n",
    "\n",
    "    return ''.join(new_seq)\n",
    "\n",
    "\n",
    "def mutate_codons(seq, aa_seq, n, mutable_codons, pptness = False):\n",
    "    assert len(seq) == 3 * len(aa_seq)\n",
    "    for _ in range(n):\n",
    "        aa_to_mut = random.choice(mutable_codons)\n",
    "        new_codon = make_nt_seq(aa_seq[aa_to_mut], pptness)\n",
    "        new_seq = seq[0:3 * aa_to_mut] + new_codon + seq[3 * aa_to_mut + 3:]\n",
    "        assert len(new_seq) == len(seq), \"idiot\"\n",
    "\n",
    "        seq = new_seq\n",
    "\n",
    "    return seq\n",
    "\n",
    "\n",
    "def mut_cds(old_cds, mut_n, mutable_codons, original_purines, less_purines = True, pptness = False):\n",
    "    \"\"\"\n",
    "    Note that mut_start and mut_end are in nucleotide coordinates\n",
    "    \"\"\"\n",
    "    # Determine which codons can be mutated\n",
    "\n",
    "    aa_seq = translate_cds(old_cds)\n",
    "\n",
    "    for _ in range(500):\n",
    "        new_cds = mutate_codons(old_cds, aa_seq, mut_n, mutable_codons, pptness)\n",
    "        \n",
    "        if less_purines == True:\n",
    "            if sum([new_cds.upper().count(i) for i in purine_4mers]) <= original_purines:\n",
    "                if new_cds != old_cds:\n",
    "                    return new_cds\n",
    "        else:\n",
    "            if sum([new_cds.upper().count(i) for i in purine_4mers]) > original_purines:\n",
    "                if new_cds != old_cds:\n",
    "                    return new_cds\n",
    "\n",
    "    print(\"No further CDS mutations.\")\n",
    "#     break_loop = True\n",
    "    return old_cds\n",
    "\n",
    "    assert 0 == 1, \"Unable to make new sequence\"\n",
    "\n",
    "\n",
    "def get_args():\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"-i\", \"--intron_csv\", help=\"A csv of introns. First column = insert position, second = intron sequence. Don't use column headers\")\n",
    "    parser.add_argument(\"-c\", \"--initial_cds\", help=\"The CDS sequence. Only lower case letters can be mutated.\")\n",
    "    parser.add_argument(\"-o\", \"--output\", help=\"output filename\")\n",
    "    parser.add_argument(\"--upstream_seq\", help=\"5'utr\", default=\"\")\n",
    "    parser.add_argument(\"--downstream_seq\", help=\"3'utr\", default=\"\")\n",
    "    parser.add_argument(\"-n\", \"--n_iterations\", type=int, default=500)\n",
    "    parser.add_argument(\"--skip_tf\", action=\"store_true\")\n",
    "    parser.add_argument(\"--chance_intron_move\", default=0.3, type=float)\n",
    "    parser.add_argument(\"--max_intron_move\", default=15, type=int)\n",
    "    parser.add_argument(\"--n_codons_mut\", default=5, type=int)\n",
    "    parser.add_argument(\"--chance_intron_mut\", default=0.3, type=float)\n",
    "    parser.add_argument(\"--intron_mut_rate\", default=0.05, type=float, help=\"fraction of intronic bases that get mutated\")\n",
    "    args = parser.parse_args()\n",
    "\n",
    "\n",
    "    args.aa = translate_cds(args.initial_cds)\n",
    "\n",
    "    return args\n",
    "\n",
    "\n",
    "def mut_noncoding(seq, positions_to_mut, n_mut):\n",
    "    assert len([1 for a in list(seq) if a.islower()]) > 0, \"Only lower case bases can be mutated!\"\n",
    "\n",
    "    seq = list(seq)\n",
    "    new_seq = seq\n",
    "    choices = random.choices(positions_to_mut, k=n_mut)\n",
    "    for i in choices:\n",
    "        new_seq[i] = random.choice([\"a\", \"t\", \"c\", \"g\"])\n",
    "\n",
    "    return ''.join(new_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "args = parser.parse_args(\"\")\n",
    "\n",
    "cds_file = \"/camp/lab/ulej/home/users/farawar/GASR/export_reporter/ppig_deoptimised_4m_with_mSc.txt\"\n",
    "utr5_file = \"/camp/lab/ulej/home/users/farawar/GASR/export_reporter/5utr.txt\"\n",
    "utr3_file = \"/camp/lab/ulej/home/users/farawar/GASR/export_reporter/3utr.txt\"\n",
    "    \n",
    "args.intron_csv = \"/camp/lab/ulej/home/users/farawar/GASR/export_reporter/best_introns/best_introns.csv\"\n",
    "# args.intron_csv = \"/camp/lab/ulej/home/users/farawar/GASR/export_reporter/best_introns/test_introns.csv\"\n",
    "    \n",
    "with open(cds_file) as file:\n",
    "    args.initial_cds = file.read().rstrip().lower()\n",
    "\n",
    "with open(utr5_file) as file:\n",
    "    args.upstream_seq = file.read().rstrip().lower()\n",
    "\n",
    "with open(utr3_file) as file:\n",
    "    args.downstream_seq = file.read().rstrip().lower()\n",
    "\n",
    "args.output = \"/camp/lab/ulej/home/users/farawar/GASR/export_reporter/best_introns/output/reporter\"\n",
    "args.n = 1000\n",
    "args.skip_tf = False\n",
    "args.chance_intron_move = 0.3\n",
    "args.max_intron_move = 20\n",
    "args.n_codons_mut = 5\n",
    "args.chance_intron_mut = 0.5\n",
    "args.intron_mut_rate = 0.05\n",
    "args.aa = translate_cds(args.initial_cds)\n",
    "\n",
    "purines = ['A', 'G']\n",
    "\n",
    "raw_purine_4mers = [''.join(i) for i in itertools.product(purines, repeat = 4)] #Create all purinergic 4-mers\n",
    "purine_4mers = [mer for mer in raw_purine_4mers[1:] if not \"GGG\" in mer] #No AAAA, no GGG.\n",
    "purine_4mers = [i for i in purine_4mers if i.count('G') < 3] #Nothing with 3 Gs fuck that shit bro (G is a cringe purine)\n",
    "original_purine_4mers = sum([args.initial_cds.upper().count(i) for i in purine_4mers])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"--skip_tf\" in sys.argv:\n",
    "    load_tf = False\n",
    "else:\n",
    "    load_tf = True\n",
    "\n",
    "if load_tf:\n",
    "    from keras.models import load_model\n",
    "    from pkg_resources import resource_filename\n",
    "    from spliceai.utils import one_hot_encode\n",
    "\n",
    "    paths = ('models/spliceai{}.h5'.format(x) for x in range(1, 6))\n",
    "    models = [load_model(resource_filename('spliceai', x)) for x in paths]\n",
    "\n",
    "\n",
    "    def get_probs(input_sequence):\n",
    "        context = 10000\n",
    "        x = one_hot_encode('N' * (context // 2) + input_sequence + 'N' * (context // 2))[None, :]\n",
    "        y = np.mean([models[m].predict(x) for m in range(5)], axis=0)\n",
    "\n",
    "        acceptor_prob = y[0, :, 1]\n",
    "        donor_prob = y[0, :, 2]\n",
    "\n",
    "        return acceptor_prob, donor_prob\n",
    "else:\n",
    "    print(\"NOT LOADING TENSOR FLOW! THIS IS JUST FOR TESTS\")\n",
    "\n",
    "\n",
    "    def get_probs(input_sequence):\n",
    "        return [0] * len(input_sequence), [0] * len(input_sequence)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Read in introns:\n",
    "intron_d = {}\n",
    "with open(args.intron_csv) as file:\n",
    "    for line in file:\n",
    "        split = line.rstrip().split(\",\")\n",
    "        # assert len(split) == 2 or (len(split) == 3 and split[-1] == \"\"), \"Too many columns\"\n",
    "\n",
    "        intron_d[int(split[0])] = split[1]\n",
    "\n",
    "total_intron_l = sum([len(a) for a in intron_d.values()])\n",
    "\n",
    "\n",
    "mutable_codons = []\n",
    "for i in range(int(len(args.initial_cds)/3)):\n",
    "    this_codon = args.initial_cds[3*i:3*i+3]\n",
    "    total_lower = sum([1 for a in this_codon if a.islower()])\n",
    "    assert total_lower in [0, 3], \"Codons must either be upper or lower case. Cannot be a mix!\"\n",
    "    if total_lower == 3:\n",
    "        mutable_codons.append(i)\n",
    "        \n",
    "best_score = -10000000\n",
    "best_switches = {position:0 for position in intron_d.keys()}\n",
    "best_intron_d = dict(intron_d)\n",
    "n_purines = original_purine_4mers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(args.n):\n",
    "# for i in range(50):\n",
    "\n",
    "    if i % 50 == 0:\n",
    "        print(\"iteration \" + str(i))\n",
    "\n",
    "    if i == 0:\n",
    "        best_cds = args.initial_cds\n",
    "        new_cds = args.initial_cds\n",
    "        new_switches = dict(best_switches)\n",
    "        new_intron_d = dict(intron_d)\n",
    "        break_loop = False\n",
    "    else:\n",
    "        for _ in range(100):\n",
    "            new_cds = mut_cds(best_cds, args.n_codons_mut, mutable_codons, n_purines, True)\n",
    "            new_gc = sum([new_cds.upper().count(i) for i in ['G', 'C']])/len(new_cds)\n",
    "            if new_gc - .5 < 0.05: # Don't allow GC content to go above 55?\n",
    "                continue\n",
    "            else:\n",
    "                new_cds = best_cds\n",
    "        \n",
    "        if random.randint(0,100) < 100*args.chance_intron_mut:\n",
    "            \n",
    "            # pick a random key based on how strong the intron is. Add 0.05 to keep things a bit random.\n",
    "            new_intron_d = dict(best_intron_d)\n",
    "\n",
    "            all_keys = list(new_intron_d.keys())\n",
    "            inverse_summed_probs = [(2 - (a + b)) + 0.05 for a, b in zip([donor_prob[a] for a in donors], [acceptor_prob[a] for a in acceptors])]\n",
    "            choice_weights = inverse_summed_probs/sum(inverse_summed_probs)\n",
    "            key_index = np.random.choice(range(len(all_keys)), size = 1, p = choice_weights, replace = False)[0]\n",
    "            key_choice = all_keys[key_index]\n",
    "            \n",
    "            seq_list = list(new_intron_d[key_choice])\n",
    "\n",
    "            #If the expected donors and acceptors are good, we don't want to mutate them.\n",
    "            current_donor_probs = donor_prob[donors[key_index]:(acceptors[key_index] + 1)]\n",
    "            current_donor_probs[0] = 0\n",
    "\n",
    "            current_acceptor_probs = acceptor_prob[donors[key_index]:(acceptors[key_index] + 1)]\n",
    "            current_acceptor_probs[-1] = 0\n",
    "\n",
    "            kernel = np.ones(9)/9\n",
    "            smooth_donors = np.convolve(current_donor_probs, kernel, mode = \"same\")[1:-1]\n",
    "            smooth_acceptors = np.convolve(current_acceptor_probs, kernel, mode = \"same\")[1:-1]\n",
    "            smooth_probs = smooth_donors + smooth_acceptors + 0.01 #Add a constant to slightly deprioritise splice sites\n",
    "\n",
    "            #Normalise the probabilities\n",
    "            smooth_probs = smooth_probs/sum(smooth_probs)\n",
    "\n",
    "            int_len = len(new_intron_d[key_choice])\n",
    "            n_mut = round(int_len * args.intron_mut_rate)\n",
    "            mutation_index = np.random.choice(range(int_len), size = n_mut, p = smooth_probs, replace = False).astype('int')\n",
    "\n",
    "            replacement_nt = random.choices([\"A\", \"C\", \"G\", \"T\"], k = n_mut)\n",
    "\n",
    "            for a, i in enumerate(mutation_index):\n",
    "                seq_list[i] = replacement_nt[a]\n",
    "            \n",
    "            new_intron_d[key_choice] = ''.join(seq_list)\n",
    "        else:\n",
    "            new_intron_d = dict(best_intron_d)\n",
    "            \n",
    "        if random.randint(0,100) < 100*args.chance_intron_move:\n",
    "            # move an intron position\n",
    "            new_switches = dict(best_switches)\n",
    "            all_keys = list(new_switches.keys())\n",
    "            key_choice = random.choice(all_keys)\n",
    "            new_switches[key_choice] = random.randint(-args.max_intron_move, args.max_intron_move)\n",
    "        else:\n",
    "            new_switches = dict(best_switches)\n",
    "    \n",
    "    new_combined_seq = args.upstream_seq\n",
    "    p = 0\n",
    "    for intron_start, intron_seq in new_intron_d.items():\n",
    "        intron_start2 = intron_start + new_switches[intron_start]\n",
    "        new_combined_seq += new_cds[p:intron_start2]\n",
    "        p = intron_start2\n",
    "        new_combined_seq += intron_seq\n",
    "    new_combined_seq += new_cds[p:]\n",
    "    new_combined_seq += args.downstream_seq\n",
    "    \n",
    "    donors = []\n",
    "    acceptors = []\n",
    "    pos = len(args.upstream_seq)\n",
    "    prev_intron_start = 0\n",
    "    for intron_start, intron_seq in new_intron_d.items():\n",
    "        intron_start2 = intron_start + new_switches[intron_start]\n",
    "        pos += intron_start2-prev_intron_start\n",
    "        prev_intron_start = intron_start2\n",
    "        donors.append(pos-1)  # subtract 1 for donors idk why\n",
    "        pos += len(intron_seq)\n",
    "        acceptors.append(pos)\n",
    "\n",
    "    acceptor_prob, donor_prob = get_probs(new_combined_seq)\n",
    "\n",
    "    score = sum([acceptor_prob[a] for a in acceptors])\n",
    "    score += sum([donor_prob[a] for a in donors])\n",
    "    score += sum([-b for a, b in enumerate(acceptor_prob) if a not in acceptors])\n",
    "    score += sum([-b for a, b in enumerate(donor_prob) if a not in donors])\n",
    "\n",
    "    \n",
    "    if score > best_score:\n",
    "        best_score = score\n",
    "        best_cds = new_cds\n",
    "        n_purines = sum([best_cds.upper().count(i) for i in purine_4mers])\n",
    "        best_switches = dict(new_switches)\n",
    "        best_combined = new_combined_seq\n",
    "        best_donor_prob = donor_prob\n",
    "        best_acceptor_prob = acceptor_prob\n",
    "        best_intron_d = dict(new_intron_d)\n",
    "        best_donors = donors\n",
    "        best_acceptors = acceptors\n",
    "\n",
    "        print(\"\")\n",
    "        print(score)\n",
    "        print(best_switches)\n",
    "        #print(best_cds)\n",
    "        print(\"donor_scores:\")\n",
    "        print([donor_prob[a] for a in donors])\n",
    "        print(\"acceptor_scores:\")\n",
    "        print([acceptor_prob[a] for a in acceptors])\n",
    "        print(\"Purine content:\")\n",
    "        print(n_purines)\n",
    "        print(\"GC content:\")\n",
    "        print(sum([best_cds.upper().count(i) for i in ['G', 'C']])/len(best_cds))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(args.output + \".low_purine.output.csv\", 'w') as file:\n",
    "    file.write(\"key,value\\n\")\n",
    "    file.write(\"full_sequence,\" + new_combined_seq + \"\\n\")\n",
    "    file.write(\"cds,\" + best_cds + \"\\n\")\n",
    "    file.write(\"score,\" + str(best_score) + \"\\n\")\n",
    "    l = len(args.upstream_seq)\n",
    "    j = 0\n",
    "    for key, value in best_intron_d.items():\n",
    "        intron_start2 = best_donors[j]\n",
    "        j+=1\n",
    "\n",
    "        file.write(\"intron_\" + str(j) + \"_start,\" +  str(intron_start2) + \"\\n\")\n",
    "        file.write(\"intron_\" + str(j) + \"_end,\" +  str(intron_start2 + len(value)) + \"\\n\")\n",
    "\n",
    "with open(args.output + \".low_purine.predictions.csv\", 'w') as file:\n",
    "    file.write(\"position,donor,acceptor\\n\")\n",
    "    yo = 0\n",
    "    for d, a in zip(list(best_donor_prob), list(best_acceptor_prob)):\n",
    "        file.write(str(yo) + \",\" + str(d) + \",\" + str(a) + \"\\n\")\n",
    "        yo += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "breakpoints = [i + j for i, j in best_switches.items()]\n",
    "midpoints = [round(j - ((j - breakpoints[i])/2)) for i, j in enumerate(breakpoints[1:])]\n",
    "\n",
    "span = range(-30,30)\n",
    "\n",
    "overlap_starts = []\n",
    "overlap_ends = []\n",
    "\n",
    "for i in midpoints:\n",
    "\n",
    "    possible_breaks = [best_cds.upper()[((i - 15) + j):((i + 14) + j)] for j in span]\n",
    "    break_purines = [sum([j.count(i) for i in purine_4mers]) for j in possible_breaks]\n",
    "\n",
    "    index_max = np.argmax(break_purines)\n",
    "    overlap_starts.append((i - 15) + span[index_max])\n",
    "    overlap_ends.append((i + 14) + span[index_max])\n",
    "\n",
    "overlap_cds = best_cds.lower()\n",
    "\n",
    "for i, j in zip(overlap_starts, overlap_ends):\n",
    "    overlap_cds = overlap_cds[:i] + overlap_cds[i:j].upper() + overlap_cds[j:]    \n",
    "\n",
    "with open(args.output + \".overlap_cds_positions.csv\", 'w') as file:\n",
    "    file.write(\"overlap_start, overlap_end, overlap_sequence\" + \"\\n\")\n",
    "    for i, j in zip(overlap_starts, overlap_ends):\n",
    "        file.write(str(i) + \", \" + str(j) + \", \" + str(overlap_cds[i:j]) + \"\\n\")\n",
    "\n",
    "deopt_purine_content = sum([overlap_cds.upper().count(i) for i in purine_4mers])\n",
    "deopt_score = score + 0\n",
    "# deopt_score = 15.904753000573976\n",
    "deopt_gc = sum([overlap_cds.upper().count(i) for i in ['G', 'C']])/len(overlap_cds)\n",
    "\n",
    "mutable_codons = []\n",
    "for i in range(int(len(overlap_cds)/3)):\n",
    "    this_codon = overlap_cds[3*i:3*i+3]\n",
    "    total_lower = sum([1 for a in this_codon if a.islower()])\n",
    "#     assert total_lower in [0, 3], \"Codons must either be upper or lower case. Cannot be a mix!\"\n",
    "    if total_lower > 0: #If there is a single capital letter, protect the whole codon.\n",
    "        mutable_codons.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(args.n):\n",
    "\n",
    "    if i % 50 == 0:\n",
    "        print(\"iteration \" + str(i))\n",
    "\n",
    "    if i == 0:\n",
    "        best_cds_p = overlap_cds\n",
    "        new_cds_p = overlap_cds\n",
    "        best_score = deopt_score\n",
    "        curent_gc = deopt_gc\n",
    "    else:\n",
    "        for _ in range(100):\n",
    "            new_cds_p = mut_cds(best_cds_p, args.n_codons_mut, mutable_codons, n_purines, False)\n",
    "            new_gc = sum([new_cds_p.upper().count(i) for i in ['G', 'C']])/len(new_cds_p)\n",
    "            if abs(new_gc - deopt_gc) < 0.03:\n",
    "                continue\n",
    "            else:\n",
    "                new_cds_p = best_cds_p\n",
    "    \n",
    "    new_combined_seq_p = args.upstream_seq\n",
    "    p = 0\n",
    "    for intron_start, intron_seq in best_intron_d.items():\n",
    "        intron_start2 = intron_start + best_switches[intron_start]\n",
    "        new_combined_seq_p += new_cds_p[p:intron_start2]\n",
    "        p = intron_start2\n",
    "        new_combined_seq_p += intron_seq\n",
    "    new_combined_seq_p += new_cds_p[p:]\n",
    "    new_combined_seq_p += args.downstream_seq\n",
    "    \n",
    "    acceptor_prob, donor_prob = get_probs(new_combined_seq_p)\n",
    "\n",
    "    score = sum([acceptor_prob[a] for a in acceptors])\n",
    "    score += sum([donor_prob[a] for a in donors])\n",
    "    score += sum([-b for a, b in enumerate(acceptor_prob) if a not in acceptors])\n",
    "    score += sum([-b for a, b in enumerate(donor_prob) if a not in donors])\n",
    "    \n",
    "    if not (sum([acceptor_prob[a] < 0.98 for a in acceptors]) & sum([donor_prob[a] < 0.98 for a in donors])):\n",
    "        if (deopt_score - score) < 0.1:\n",
    "            best_cds_p = new_cds_p\n",
    "            n_purines = sum([best_cds_p.upper().count(i) for i in purine_4mers])\n",
    "            best_combined_p = new_combined_seq_p\n",
    "            best_donor_prob = donor_prob\n",
    "            best_acceptor_prob = acceptor_prob\n",
    "            print(\"\")\n",
    "            print(score)\n",
    "            print(\"Purine content\")\n",
    "            print(n_purines)\n",
    "            print(\"GC content\")\n",
    "            print(new_gc)\n",
    "            print(\"donor_scores:\")\n",
    "            print([donor_prob[a] for a in donors])\n",
    "            print(\"acceptor_scores:\")\n",
    "            print([acceptor_prob[a] for a in acceptors])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(args.output + \".high_purine.output.csv\", 'w') as file:\n",
    "    file.write(\"key,value\\n\")\n",
    "    file.write(\"full_sequence,\" + new_combined_seq_p + \"\\n\")\n",
    "    file.write(\"cds,\" + best_cds_p + \"\\n\")\n",
    "    file.write(\"score,\" + str(best_score) + \"\\n\")\n",
    "    l = len(args.upstream_seq)\n",
    "    j = 0\n",
    "    for key, value in best_intron_d.items():\n",
    "        intron_start2 = best_donors[j]\n",
    "        j+=1\n",
    "\n",
    "        file.write(\"intron_\" + str(j) + \"_start,\" +  str(intron_start2) + \"\\n\")\n",
    "        file.write(\"intron_\" + str(j) + \"_end,\" +  str(intron_start2 + len(value)) + \"\\n\")\n",
    "\n",
    "with open(args.output + \".high_purine.predictions.csv\", 'w') as file:\n",
    "    file.write(\"position,donor,acceptor\\n\")\n",
    "    yo = 0\n",
    "    for d, a in zip(list(best_donor_prob), list(best_acceptor_prob)):\n",
    "        file.write(str(yo) + \",\" + str(d) + \",\" + str(a) + \"\\n\")\n",
    "        yo += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Local spliceai-jupyter",
   "language": "python3",
   "name": "rik_local_spliceaijupyter"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
